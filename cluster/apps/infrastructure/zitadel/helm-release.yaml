---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: zitadel
spec:
  interval: 15m
  chart:
    spec:
      chart: zitadel
      version: 7.14.0
      sourceRef:
        kind: HelmRepository
        name: zitadel
        namespace: flux-charts

  driftDetection:
    mode: enabled
  maxHistory: 3
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      strategy: rollback
      retries: 3

  values:
    zitadel:
      # The ZITADEL config under configmapConfig is written to a Kubernetes ConfigMap
      # See all defaults here:
      # https://github.com/zitadel/zitadel/blob/main/cmd/defaults.yaml
      configmapConfig:
        Log:
          Level: info
          Formatter:
            Format: text
        FirstInstance:
          Org:
            Machine:
              Machine:
                Username: zitadel-admin-sa
                Name: Admin
              MachineKey:
                ExpirationDate: "2026-01-01T00:00:00Z"
                # Type: 1 means JSON. This is currently the only supported machine key type.
                Type: 1
        Database:
          postgres:
            Port: 5432
            User:
              SSL:
                Mode: disable
            Admin:
              SSL:
                Mode: disable
        LogStore:
          Access:
            Stdout:
              Enabled: false

        ExternalDomain: &host zitadel.${SECRET_DOMAIN_NAME}
        ExternalSecure: true
        ExternalPort: 443
        TLS:
          Enabled: false
        WebAuthNName: ZITADEL
        # The Secret containing the root CA Certificate at key ca.crt needed for establishing secure database connections

      masterkeySecretName: zitadel-secret

      # Enabling this will create a debug pod that can be used to inspect the ZITADEL configuration and run zitadel commands using the zitadel binary.
      # This is useful for debugging and troubleshooting.
      # After the debug pod is created, you can open a shell within the pod.
      # See more instructions by printing the pods logs using kubectl logs [pod name].
      debug:
        enabled: true
        annotations:
          helm.sh/hook: pre-install,pre-upgrade
          helm.sh/hook-weight: "1"

    replicaCount: 1

    image:
      repository: ghcr.io/zitadel/zitadel
      tag: v2.51.4
      pullPolicy: IfNotPresent

    # Additional environment variables
    env:
      - name: ZITADEL_DATABASE_POSTGRES_HOST
        valueFrom:
          secretKeyRef:
            name: database-zitadel
            key: HOST
      - name: ZITADEL_DATABASE_POSTGRES_DATABASE
        valueFrom:
          secretKeyRef:
            name: database-zitadel
            key: DATABASE_NAME
      - name: ZITADEL_DATABASE_POSTGRES_USER_USERNAME
        valueFrom:
          secretKeyRef:
            name: database-zitadel
            key: LOGIN
      - name: ZITADEL_DATABASE_POSTGRES_USER_PASSWORD
        valueFrom:
          secretKeyRef:
            name: database-zitadel
            key: PASSWORD
      - name: ZITADEL_DATABASE_POSTGRES_ADMIN_USERNAME
        valueFrom:
          secretKeyRef:
            name: database-zitadel
            key: LOGIN
      - name: ZITADEL_DATABASE_POSTGRES_ADMIN_PASSWORD
        valueFrom:
          secretKeyRef:
            name: database-zitadel
            key: PASSWORD

    service:
      type: ClusterIP
      port: 8080
      protocol: http2
      annotations: { }

    ingress:
      enabled: true
      className: traefik
      hosts:
        - host: *host
          paths:
            - path: /
              pathType: Prefix

    initJob:
      # Once ZITADEL is installed, the initJob can be disabled.
      enabled: true
      command: zitadel

    readinessProbe:
      enabled: true
      initialDelaySeconds: 0
      periodSeconds: 5
      failureThreshold: 3

    livenessProbe:
      enabled: true
      initialDelaySeconds: 0
      periodSeconds: 5
      failureThreshold: 3

    startupProbe:
      enabled: true
      periodSeconds: 1
      failureThreshold: 30

    metrics:
      enabled: true
      serviceMonitor:
        enabled: true
